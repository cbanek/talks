% super simple template for automated 2018 ADASS manuscript generation from the registration entry
% place this file in your ADASS2018_author_template directory
%
% Only few comments here, see the ADASS_template.tex for a more fully commented version, and
% ManuscriptInstructions.pdf if you need more background, and if you even need more, APS's own
% manual2010.pdf has it all!

% Version 16-aug-2019 (Erik Deul)

\documentclass[11pt,twoside]{article}
\usepackage{asp2014}

\aspSuppressVolSlug
\resetcounters

\bibliographystyle{asp2014}

\markboth{Banek}{(I6.1) Why is the LSST Science Platform built on Kubernetes?}
% remove/add as you need

\begin{document}

\title{(I6.1) Why is the LSST Science Platform built on Kubernetes?}


\author{Christine~Banek$^1$}
\affil{$^1$AURA/LSST, Tucson, AZ, USA; \email{cbanek@lsst.org}}
% remove/add as you need

% remove/add authors as you need
\paperauthor{Christine~Banek}{cbanek@lsst.org}{0000-0002-4337-4956}{AURA}{LSST}{Tucson}{AZ}{85716}{USA}
% remove/add as you need

% leave these next few aindex lines commented for the editors to enable them. Use Aindex.py to generate them for yourself.
% first presenting author should be the first entry for bold-facing the author index page-reference
%\aindex{Banek,~C.}
%\aindex{Author2,~S.}
% remove/add as you need

% leave the ssindex lines commented for the editors to enable them, use Index.py to suggest yours
%\ssindex{FOOBAR!conference!ADASS 2018}
%\ssindex{FOOBAR!organisations!ASP}

% leave the ooindex lines commented for the editors to enable them, use ascl.py to suggest yours
%\ooindex{FOOBAR, ascl:1101.010}

\begin{abstract}
LSST has chosen Kubernetes as the platform for deploying and
operating the LSST Science Platform.  We first present the
background reasoning behind this decision, including both
instrument agnostic as well as LSST specific requirements.
We then discuss the basic principals of Kubernetes, and how
they are used as the basis for the LSST Science Platform.
We conclude with an example of how an outside group may
use the publicly available resources to deploy their own
instance of the LSST Science Platform, and customize it
to their needs.
\end{abstract}

\section{Introduction}

The Large Synoptic Survey Telescope (LSST) will produce a huge amount
of data over its 10 year survey. A dataset this large is not easily stored,
copied, or manipulated.  To store the data and process it, hundreds of
machines will be required.

The LSST Science Platform (LSP) provides next to data processing and real
time interaction with the data.  By allowing scientists to run their own
custom python code in Jupyter notebooks in the LSP, we place them near the data,
which allows for much higher bandwidth access to the data than between
computers on the internet, as well as access to more processing
resources for doing large scale analysis over the dataset.

\subsection{Without Reproducbility, No One Knows What You Found}

The processes and tools used to manage these systems must also scale and
support these needs.  At the core of these needs is the ability to
reproducibly run software on machines, which has always seemed easier
in theory than in practice.

Over the 10 year survey, machines will naturally fail, or be replaced.
Software will be updated and reinstalled.  The system
must be able to work assuming that some of its nodes will be offline at
any given time, because some inevitably will be with such a large number
of machines.  As the system also needs to support user demand, the system
must also be able to appropriately scale to load.

These practical demands require an automated and reliable process for
deploying new systems, or the whole system from scratch, in a reproducible
way.  If it was not automated, then too much manual effort would be involved,
taking time and resources.  Even well intentioned manual work by knowledgeble
professionals is never perfect, possibly leaving unnoticed mistakes that could
affect performance or even scientific results.

While your project may not suffer from the scale of LSST, I would argue it is
even more important to have reproducible software.  By having fewer machines,
a larger percentage of your computing resources will be unavailable if struck by
hardware or software failures, possibly to the point of degraded performance
or unavailability of the entire system.  If, however, you are lucky and your
few machines take many years to fail, it may be found too late that you cannot
easily reproduce the configuration due to software being deprecated or deleted.
Longer lived machines also have greater risk of being manually tampered with by
well meaning operators and developers attempting to quickly fix or diagnose
solutions.

Results are only as good as your ability to reproduce them, large or small.
Reproducing scientific results on a non-reproducible software platform of any size
is fraught with risks.  While software will never be perfect, by tightly controlling
the conditions in which it runs, results should at least be easily reproducible.
If it's not, no one knows if you've found a software bug or the next Nobel prize.

\subsection{The Quest for Reproducible Software}

Reproducing a working software environment is not a trivial thing, due
mostly to the number of interconnected pieces involved.  There's the software
you are trying to run (the applications themselves), libraries and runtimes that
those applications require, the operating system, and other applications running with
or by the application on the same machine. More often than not, one application
will also call another over the network, which requires knowledge of where that
application is hosted (DNS name, URL) as well.

Most software is designed to run under very controlled conditions, because
it makes software easier to write, test, and verify.  Having to support every version of every
operating system is a lot of work that doesn't make sense for many software
projects, especially when the software won't need to run under those constraints
in production.

Enter virtualization and the virtual machine (VM).  Now on your development machine running
Windows, you can run a linux server with a particular configuration that behaves just
like production.  Disk images and unattended installs for VMs provided a standard way of
creating machines with a cookie cutter configuration.

Running VMs in production was still hard.  VMs can introduce a fair amount of performance
overhead with heavy processing or disk I/O.  Each VM also has its own copy of the operating
system, libraries, and utilities, increasing the overhead of placing many VMs on the same
physical host.  Using VMs, it can be very costly to provide complete isolation of application
instances, but it was possible.  Many hybrid approaches with different flavors of machines running
a particular set of services was very popular and successful, but this lacked flexibility
in the ways a system could scale.

\subsection{Containerization}

Containers are the current industry solution to this problem.  Containers are a way of packaging
the application, its dependencies, and configuration as one unit.  Many containers can be
run on one host sharing the same kernel.  This reduces the overhead of running many containers
versus running many VMs, while still providing much of the isolation of a VM.

\footnote{Containers use various features in kernels such as namespacing and cgroups
to share the same kernel and have isolated filesystems and process spaces.}

Since containers have everything they need already installed, and without the overhead of
starting an operating system, containers can start very quickly, typically within seconds.
This makes them not only reliable but quick to start on a new machine.

Containers can also be published to the internet.  hub.docker.com allows for users to
create accounts and publish their own container images, which are basically a compressed
tar-file of the root filesystem.  This allows for anyone to download your container and
start it on their machine.

So, finally, we have a reliable method to reproduce the installation of our software.

\subsection{Kubernetes}

Kubernetes, also lovingly known as k8s, is a platform for configuring, hosting, and
running containers.  It can operate on one machine, or elasticly scale up or down to many machines.
Kubernetes provides the framework to schedule containers, starting new
containers on different machines when its previous host goes offline or becomes unresponsive.  Kubernetes
also provides tools to help with things like configuration, secrets, storage, and networking.

\section{Core Concepts of Kubernetes}

\section{Helm}

\section{Installing the LSP using Helm}

\section{Customizing the Landing Page}

\section{Publishing Your Astronomy Software with Helm}

\section{Conclusion}

This template has no bibtex file.  Look for the larger template and
Makefile how to do this. By default the {\tt Makefile} will create an
empty I6.1.bib. When you add references to this, uncomment the
line \verb+\bibliography+ below, use ``{\tt make pdf}'' to create
your beautifully looking PDF. Only use the
\verb"\citet" and \verb"\citep" macros!



\bibliography{I6.1}

% if we have space left, we might add a conference photograph here. Leave commented for now.
% \bookpartphoto[width=1.0\textwidth]{foobar.eps}{FooBar Photo (Photo: Any Photographer)}


\end{document}

